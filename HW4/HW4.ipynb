{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4\n",
    "## Afek Adler\n",
    "January 7, 2020\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# readme:\n",
    "In order to recreate the results you can choose the dataset type in the config and to descide whether or not it should be saved to a file.\n",
    "The submission file (\"ATT_results.csv\") was created by hand by merging outputs of this script (\"ATT_results1.csv\" & \"ATT_results2.csv\").\n",
    "\n",
    "For the first 3 methods I used Random Forest, so I did not standatarize the data.\n",
    "for the last model I used KNN, it could have been better to scale the covariates and maybe even do dimensionallity reduction for that purpose. But I decided to leave it as it is.\n",
    "\n",
    "As my final prediction, I submit the mean of the first 3 methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 2\n",
    "WRITE_TO_CSV = False\n",
    "ATT_RESULTS_PATH_DATA1 = \"ATT_results1.csv\"\n",
    "ATT_RESULTS_PATH_DATA2 = \"ATT_results2.csv\"\n",
    "ATT_RESULTS_PATH_DATA = ATT_RESULTS_PATH_DATA1 if DATASET ==1 else ATT_RESULTS_PATH_DATA2\n",
    "PROPENSITY_SCORES_PATH = \"models_propensity.csv\"\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>...</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>26.786273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_1 x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9  x_10  ...  x_51  x_52  x_53  \\\n",
       "1   29   C  1.0  7.0   60   85    0    0    1     0  ...     0     0     0   \n",
       "2   27   C  0.0  0.0   64  178    0    0    0     0  ...     0     0     0   \n",
       "\n",
       "   x_54  x_55  x_56  x_57  x_58  T          Y  \n",
       "1     0     0     0    45    39  1  26.786273  \n",
       "2     0     0     0    46    42  1   0.854251  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DATASET == 1:\n",
    "    df = pd.read_csv('data1.csv',index_col = 0)\n",
    "else:\n",
    "    df = pd.read_csv('data2.csv',index_col = 0)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "* We know that there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Discard feutres which containg a unique value more than 95% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those are indedd features that tend to get a specific value \n",
      "And this specific value is present more than 95% of the time:\n",
      "0.9852144939608496\n",
      "0.9775093710953769\n",
      "0.9966680549770929\n",
      "0.9735526863806747\n",
      "0.9473136193252811\n",
      "0.9808413161182841\n",
      "0.9716784673052895\n",
      "0.9777176176593086\n",
      "0.9968763015410246\n",
      "0.9593919200333194\n",
      "0.9700124947938359\n",
      "0.9975010412328197\n",
      "0.994585589337776\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "# Discard feutres which containg a unique value more than 95% of the time / low entropy\n",
    "low_entropy_columns = []\n",
    "for col in df.columns:\n",
    "    series = df[col].value_counts()/df.shape[0]\n",
    "    humogenious = entropy(series.values)\n",
    "    if humogenious <= 0.3:\n",
    "        low_entropy_columns.append(col)\n",
    "\n",
    "print(\"Those are indedd features that tend to get a specific value \\nAnd this specific value is present more than 95% of the time:\")\n",
    "for col in low_entropy_columns:\n",
    "    series = df[col].value_counts()\n",
    "    print(series.iloc[0]/df.shape[0])\n",
    "    \n",
    "columns = [col for col in df.columns if col not in low_entropy_columns]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Treat catrgorical variables - I would choose a method that will be valid for all the methods below. So for example encoding categories by their mean response value is not a good solution, because one time we predict T and the other Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "J    2561\n",
       "I     875\n",
       "L     339\n",
       "F     221\n",
       "H     215\n",
       "K     147\n",
       "B      87\n",
       "O      73\n",
       "G      72\n",
       "A      59\n",
       "N      49\n",
       "D      45\n",
       "P      25\n",
       "C      16\n",
       "E      10\n",
       "M       8\n",
       "Name: x_21, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "E    3449\n",
       "B    1273\n",
       "D      52\n",
       "A      18\n",
       "C      10\n",
       "Name: x_24, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_dtypes = df[columns].select_dtypes(include=['object'])\n",
    "for col in categorical_dtypes:\n",
    "    print(col)\n",
    "    display(categorical_dtypes[col].value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For x_21 we will join the ten categories with less than 100 samples for one category and for x_24 we will change it to boolean if E is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': 'J',\n",
       " 'I': 'I',\n",
       " 'L': 'L',\n",
       " 'F': 'F',\n",
       " 'H': 'H',\n",
       " 'K': 'K',\n",
       " 'B': 'other',\n",
       " 'O': 'other',\n",
       " 'G': 'other',\n",
       " 'A': 'other',\n",
       " 'N': 'other',\n",
       " 'D': 'other',\n",
       " 'P': 'other',\n",
       " 'C': 'other',\n",
       " 'E': 'other',\n",
       " 'M': 'other'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_21_values_counts = categorical_dtypes['x_21'].value_counts().to_dict()\n",
    "x_21_map = {i: (i  if v > 100 else 'other') for i,v in x_21_values_counts.items()}\n",
    "x_21_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make x_24 binary and x_21 to one hot encoding \n",
    "df['x_24'] = (df['x_24'] == 'E')*1\n",
    "df = pd.concat([pd.get_dummies(df['x_21'].map(x_21_map),prefix = 'x_21_'), df.drop(columns = 'x_21')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        self.best_model = None\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=True):\n",
    "        best_score = 0\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X, y)\n",
    "            if gs.best_score_ > best_score:\n",
    "                best_score = gs.best_score_\n",
    "                self.best_model = gs.best_estimator_\n",
    "            self.grid_searches[key] = gs\n",
    "        return self.best_model\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))      \n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inverse propensity score weighting\n",
    "(From Abdia)  \n",
    "\n",
    "$\\hat{\\mu}_{A T T, I P W}=\\frac{\\sum_{i=1}^{n} Z_{i} Y_{i}}{\\sum_{i=1}^{n} Z_{i}}-\\frac{\\sum_{i=1}^{n}\\left(1-Z_{i}\\right) Y_{i} e\\left(X_{i}\\right) /\\left(1-e\\left(X_{i}\\right)\\right)}{\\sum_{i=1}^{n}\\left(1-Z_{i}\\right) e\\left(X_{i}\\right) /\\left(1-e\\left(X_{i}\\right)\\right)}$  \n",
    "WE need to estimate $e(x_i) = p(x_i = 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in df.columns if col.startswith('x')]\n",
    "X = df[x_cols]\n",
    "Y = df['T']\n",
    "atts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for lr.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    2.8s finished\n",
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for rf.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for mlp.\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 out of   5 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done   5 out of   5 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model : \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# naive solution\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "models = {\n",
    "    'lr': LogisticRegression(),'rf': RandomForestClassifier(),'mlp':MLPClassifier()}\n",
    "params = {\n",
    "    'lr': [{'solver': ['lbfgs'],'C': [2], 'class_weight':['balanced']},\n",
    "           {'solver': ['lbfgs'],'C': [0.1,0.2,1], 'class_weight':['balanced']} ],\n",
    "    'rf':[{'n_estimators' : [100], 'max_depth':[3,4,5,None]}],\n",
    "    'mlp': [{'hidden_layer_sizes': [(10,5)]}]}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "best_model = helper.fit(X, Y, scoring='roc_auc', n_jobs=8, cv =5)\n",
    "helper.score_summary(sort_by='max_score')\n",
    "print('best model : ')\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.311875</td>\n",
       "      <td>0.022912</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.739134</td>\n",
       "      <td>0.703729</td>\n",
       "      <td>0.767387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725731</td>\n",
       "      <td>0.027182</td>\n",
       "      <td>4</td>\n",
       "      <td>0.742774</td>\n",
       "      <td>0.754634</td>\n",
       "      <td>0.744282</td>\n",
       "      <td>0.747800</td>\n",
       "      <td>0.754359</td>\n",
       "      <td>0.748770</td>\n",
       "      <td>0.004953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349371</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>0.021144</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.736539</td>\n",
       "      <td>0.705677</td>\n",
       "      <td>0.767943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727365</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>2</td>\n",
       "      <td>0.766111</td>\n",
       "      <td>0.776815</td>\n",
       "      <td>0.765843</td>\n",
       "      <td>0.768865</td>\n",
       "      <td>0.778117</td>\n",
       "      <td>0.771150</td>\n",
       "      <td>0.005280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.384371</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>0.020146</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.748243</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>0.772256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732126</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>0.809594</td>\n",
       "      <td>0.799372</td>\n",
       "      <td>0.801298</td>\n",
       "      <td>0.810391</td>\n",
       "      <td>0.804327</td>\n",
       "      <td>0.004679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.778515</td>\n",
       "      <td>0.057882</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.705817</td>\n",
       "      <td>0.765099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726216</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.311875      0.022912         0.020346        0.001954   \n",
       "1       0.349371      0.019282         0.021144        0.000399   \n",
       "2       0.384371      0.008776         0.020146        0.000977   \n",
       "3       0.778515      0.057882         0.022739        0.002475   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0               3                100   \n",
       "1               4                100   \n",
       "2               5                100   \n",
       "3            None                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 3, 'n_estimators': 100}           0.739134   \n",
       "1     {'max_depth': 4, 'n_estimators': 100}           0.736539   \n",
       "2     {'max_depth': 5, 'n_estimators': 100}           0.748243   \n",
       "3  {'max_depth': None, 'n_estimators': 100}           0.746324   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0           0.703729           0.767387  ...         0.725731        0.027182   \n",
       "1           0.705677           0.767943  ...         0.727365        0.024266   \n",
       "2           0.710835           0.772256  ...         0.732126        0.025365   \n",
       "3           0.705817           0.765099  ...         0.726216        0.025207   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                4            0.742774            0.754634   \n",
       "1                2            0.766111            0.776815   \n",
       "2                1            0.800980            0.809594   \n",
       "3                3            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.744282            0.747800            0.754359   \n",
       "1            0.765843            0.768865            0.778117   \n",
       "2            0.799372            0.801298            0.810391   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.748770         0.004953  \n",
       "1          0.771150         0.005280  \n",
       "2          0.804327         0.004679  \n",
       "3          1.000000         0.000000  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can look at the train vs test score of our best model in order to see how much we are over (under) fitting.\n",
    "In fact, anyhow, i will not further fine tune the best model.\n",
    "\"\"\"\n",
    "pd.DataFrame(helper.grid_searches['rf'].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5581220732948005"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATT results\n",
    "v = best_model.predict_proba(X)[:,1]/best_model.predict_proba(X)[:,0]\n",
    "ATT = (df['T']*df['Y']).sum()/(df['T'].sum()) - ((1-df['T'])*df['Y']*v).sum()/((1-df['T'])*v).sum()\n",
    "propensity_scores = pd.DataFrame(best_model.predict_proba(X)[:,1]).T\n",
    "propensity_scores.index = ['data1' if DATASET == 1 else 'data2']\n",
    "atts['1'] = ATT\n",
    "ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. S Learner\n",
    "$\\hat{y} = f(x,t) \\rightarrow$  \n",
    "$CATE(x) = f(x,1) - f(x,0) \\rightarrow$  \n",
    "$ATT = \\sum_{i\\\n",
    "in \\{T =1\\}}f(x,1) - f(x,0)$  \n",
    "We need to fit a model $\\hat{y} = f(x,t) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[x_cols+['T']]\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for lr.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Running GridSearchCV for rf.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model : \n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "models = {\n",
    "    'lr':  Ridge(),'rf': RandomForestRegressor()}\n",
    "params = {\n",
    "    'lr': [{'alpha':[0.1,0.5,1]}],\n",
    "    'rf':[{'n_estimators' : [100], 'max_depth':[3,4,5,None]}]}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "best_model = helper.fit(X, Y, n_jobs=8, cv =5)\n",
    "helper.score_summary(sort_by='max_score')\n",
    "print('best model : ')\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.800755</td>\n",
       "      <td>0.776987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 100}</td>\n",
       "      <td>0.871686</td>\n",
       "      <td>0.850353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.909522</td>\n",
       "      <td>0.888914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 100}</td>\n",
       "      <td>0.990618</td>\n",
       "      <td>0.930802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_train_score  mean_test_score\n",
       "0     {'max_depth': 3, 'n_estimators': 100}          0.800755         0.776987\n",
       "1     {'max_depth': 4, 'n_estimators': 100}          0.871686         0.850353\n",
       "2     {'max_depth': 5, 'n_estimators': 100}          0.909522         0.888914\n",
       "3  {'max_depth': None, 'n_estimators': 100}          0.990618         0.930802"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(helper.grid_searches['rf'].cv_results_)[['params','mean_train_score','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.212959612199516"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = X[X['T'] == 1]\n",
    "x0 = x1.copy()\n",
    "x0['T'] = 0\n",
    "ATT = np.mean(best_model.predict(x1)- best_model.predict(x0))\n",
    "atts['2'] = ATT\n",
    "ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. T Learner\n",
    "model #1 $\\hat{y_1} = f(x,t = 1) = f_1$  \n",
    "model #2 $\\hat{y_0} = f(x,t = 0) = f_0$\n",
    "\n",
    "$CATE(x) = f_1(x) - f_0(x) \\rightarrow$  \n",
    "$ATT = \\sum_{i\\in \\{T=1\\}}f_1(x) - f_0(x)$  \n",
    "We need to fit 2 models $f_0, f_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = df[df['T'] == 0][x_cols]\n",
    "Y_0 = df[df['T'] == 0]['Y']\n",
    "X_1 = df[df['T'] == 1][x_cols]\n",
    "Y_1 = df[df['T'] == 1]['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for lr.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Running GridSearchCV for rf.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model : \n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "models = {\n",
    "    'lr':  Ridge(),'rf': RandomForestRegressor()}\n",
    "params = {\n",
    "    'lr': [{'alpha':[0.1,0.5,1]}],\n",
    "    'rf':[{'n_estimators' : [100], 'max_depth':[3,4,5,None]}]}\n",
    "\n",
    "helper = EstimatorSelectionHelper(models, params)\n",
    "best_model = helper.fit(X_0, Y_0, n_jobs=8, cv =5)\n",
    "helper.score_summary(sort_by='max_score')\n",
    "print('best model : ')\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for lr.\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Running GridSearchCV for rf.\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model : \n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afeki\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model1 = helper.fit(X_1, Y_1, n_jobs=8, cv =5)\n",
    "helper.score_summary(\n",
    "    sort_by='max_score')\n",
    "print('best model : ')\n",
    "print (best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATT = np.mean(best_model1.predict(X_1)- best_model.predict(X_1))\n",
    "atts['3'] = ATT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Matching\n",
    "For each $x_i \\in \\{T = 1\\}$  estimate $y_0^i $ based on $x_i$ nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_0,Y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.371270606026528"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATT = np.mean(Y_1.values - knn.predict(X_1)) \n",
    "atts['4'] = ATT\n",
    "ATT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_TO_CSV:\n",
    "    propensity_scores.to_csv(PROPENSITY_SCORES_PATH, mode = 'a',header = None)\n",
    "    pd.Series(atts).to_frame().to_csv(ATT_RESULTS_PATH_DATA,header = None, index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
